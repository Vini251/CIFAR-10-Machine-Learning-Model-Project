{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Project\n",
    "\n",
    "DataSet: CIFAR-10\n",
    "\n",
    "Introduction:\n",
    "The CIFAR-10 dataset (Canadian Institute for Advanced Research, 10 classes) is a subset of the Tiny Images dataset and consists of 60000 32x32 color images. The images are labelled with one of 10 mutually exclusive classes: airplane, automobile (but not truck or pickup truck), bird, cat, deer, dog, frog, horse, ship, and truck (but not pickup truck). There are 6000 images per class with 5000 training and 1000 testing images per class.\n",
    "\n",
    "Dataset overview:\n",
    "Classes in dataset:\n",
    "1. airplane\n",
    "2. automobile\n",
    "3. bird\n",
    "4. cat\n",
    "5. deer\n",
    "6. dog\n",
    "7. frog\n",
    "8. horse\n",
    "9. ship\n",
    "10. truck\n",
    "\n",
    "\n",
    "Classifer:  Logistic Classifier\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the modules needed to train the logistic model on the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, learning_curve, GridSearchCV\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from itertools import product\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "seed = 1234"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset to the assigned variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unpickle(file):\n",
    "#     with open(file, 'rb') as fo:\n",
    "#         dict = pickle.load(fo, encoding='bytes')\n",
    "#     return dict\n",
    "\n",
    "# def load_cifar10_data(data_dir):\n",
    "#     # Load training data\n",
    "#     X_train = []\n",
    "#     y_train = []\n",
    "#     for i in range(1, 6):\n",
    "#         batch = unpickle(data_dir + '/data_batch_' + str(i))\n",
    "#         X_train.append(batch[b'data'])\n",
    "#         y_train.append(batch[b'labels'])\n",
    "#     X_train = np.concatenate(X_train, axis=0)\n",
    "#     y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "#     # Load test data\n",
    "#     test_batch = unpickle(data_dir + '/test_batch')\n",
    "#     X_test = test_batch[b'data']\n",
    "#     y_test = np.array(test_batch[b'labels'])\n",
    "\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=seed)\n",
    "\n",
    "#     return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# Load in the data\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    " \n",
    "# Distribute it to train and test set\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# creating 80%/10%/10% split\n",
    "# 80% for training, 10% for validation (dev set), 10% for test\n",
    "\n",
    "X= np.concatenate((X_train, X_test))\n",
    "y= np.concatenate((y_train, y_test))\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "# test set provided is already 20% of data\n",
    "# getting 60% training and 20% val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, shuffle=True, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = 'cifar-10-batches-py'\n",
    "# X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10_data(data_dir)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre processing\n",
    "# flatten y to 1D\n",
    "y_train = y_train.flatten()\n",
    "y_val = y_val.flatten()\n",
    "y_test = y_test.flatten()\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# sub-sampling\n",
    "# create smaller training set with first 13k images\n",
    "# want a sub sampled training set that has more data than the isolated test set\n",
    "# training set = 13,000 sub-sample\n",
    "X_train = X_train[:13000]\n",
    "y_train = y_train[:13000]\n",
    "\n",
    "# reshape x\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1)).astype(\"float32\")\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], -1)).astype(\"float32\")\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1)).astype(\"float32\")\n",
    "\n",
    "\n",
    "# standardize data\n",
    "# want to standardize data to a range of 0 to 1\n",
    "# dividing by 255 because pixel values range from 0-255\n",
    "X_train = X_train/255.0\n",
    "X_val = X_val/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "# Convert target labels to one-hot encoding\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=10)\n",
    "y_val_one_hot = to_categorical(y_val, num_classes=10)\n",
    "\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training with only 2 layers\n",
    "activation_func = ['relu', 'relu', 'sigmoid', 'relu','sigmoid', 'relu']\n",
    "learning_rates = [0.0001, 0.001, 0.05, 0.01, 0.1, 0.5,]\n",
    "weight1 = [200, 150, 128, 1024, 250, 512]\n",
    "weight2 = [100, 256, 120, 512, 310, 245]\n",
    "# weight3 = [10, 10, 25, 10, 40, 75]\n",
    "epochs= [5, 50, 20, 100, 15, 10]\n",
    "batch_sizes = [20, 10, 30, 32, 50, 45]\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(weight1[i], input_shape=(3072,), activation=activation_func[i]))\n",
    "    model.add(Dense(weight2[i], activation=activation_func[i]))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    # train the model using SGD\n",
    "    print(\"[INFO] training network...\")\n",
    "    sgd = SGD(learning_rates[i])\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "    H = model.fit(X_train, y_train, validation_data=(X_val, y_val_one_hot), epochs=epochs[i], batch_size=batch_sizes[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the hyperparameters to iterate over\n",
    "penalty_options = ['l1', 'l2']\n",
    "c_values = [10, 1.0, 0.1, 0.01, 0.001]\n",
    "\n",
    "# Initialize variables to store the best hyperparameters and accuracy\n",
    "best_accuracy = 0.0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "# Initialize lists to store the error rates and corresponding hyperparameters\n",
    "train_error_rates = []\n",
    "val_error_rates = []\n",
    "hyperparameter_combinations = []\n",
    "\n",
    "# Iterate over the hyperparameter combinations\n",
    "for penalty in penalty_options:\n",
    "    for c in c_values:\n",
    "        print(penalty, c)\n",
    "        # Create the logistic regression model with the current hyperparameters\n",
    "        logistic_model = LogisticRegression(penalty=penalty, C=c, solver='saga')\n",
    "        \n",
    "        # Fit the model to the training data\n",
    "        logistic_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate the model on the train set\n",
    "        train_predictions = logistic_model.predict(X_train)\n",
    "        train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "        train_error_rate = 1 - train_accuracy\n",
    "        train_error_rates.append(train_error_rate)\n",
    "        \n",
    "        # Evaluate the model on the validation set\n",
    "        val_predictions = logistic_model.predict(X_val)    \n",
    "        val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "        val_error_rate = 1 - val_accuracy\n",
    "        val_error_rates.append(val_error_rate)\n",
    "\n",
    "        hyperparameter_combinations.append((penalty, c))\n",
    "        \n",
    "        # Check if this combination has better accuracy than the previous best\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            best_hyperparameters = {'penalty': penalty, 'c': c}\n",
    "\n",
    "# Convert the hyperparameter combinations into strings for plotting\n",
    "hyperparameter_combinations = [str(combination) for combination in hyperparameter_combinations]\n",
    "\n",
    "# Print the best hyperparameters and accuracy\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Validation Accuracy:\", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a line plot of the error rates\n",
    "plt.plot(hyperparameter_combinations, train_error_rates, marker='o', label='Train')\n",
    "plt.plot(hyperparameter_combinations, val_error_rates, marker='o', label='Validation')\n",
    "plt.xlabel('Hyperparameter Combinations')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.title('Error Rate for Different Hyperparameter Combinations')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the classifier\n",
    "logistic_model = LogisticRegression(penalty=\"l2\", C=0.001, solver='saga')\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = logistic_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "confusionMatrix = confusion_matrix(y_train, y_pred_train)\n",
    "confusionMatrix = ConfusionMatrixDisplay(confusion_matrix = confusionMatrix)\n",
    "confusionMatrix.plot()\n",
    "print(\"Precision:\", precision_score(y_train, y_pred_train, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_train, y_pred_train, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the classifier on the validation set\n",
    "y_pred_val = logistic_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "confusionMatrix = confusion_matrix(y_val, y_pred_val)\n",
    "confusionMatrix = ConfusionMatrixDisplay(confusion_matrix= confusionMatrix)\n",
    "confusionMatrix.plot()\n",
    "print(\"Precision:\", precision_score(y_val, y_pred_val, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_val, y_pred_val, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the classifier\n",
    "y_pred_test = logistic_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "confusionMatrix = confusion_matrix(y_test, y_pred_test)\n",
    "confusionMatrix = ConfusionMatrixDisplay(confusion_matrix= confusionMatrix)\n",
    "confusionMatrix.plot()\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(penalty=\"l2\", C=0.001, solver='saga')\n",
    "train_sizes = [0.01, 0.1, 0.25, 0.5, 0.8]\n",
    "train_sizes, train_scores, val_scores = learning_curve(estimator=logistic_model, X=X_train, y=y_train, train_sizes=train_sizes, cv=5, shuffle=True)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "val_scores_mean = np.mean(val_scores, axis=1)\n",
    "val_scores_std = np.std(val_scores, axis=1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_scores_mean, label='Training Score', color='blue')\n",
    "plt.plot(train_sizes, val_scores_mean, label='Validation Score', color='red')\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.3, color='blue')\n",
    "plt.fill_between(train_sizes, val_scores_mean - val_scores_std, val_scores_mean + val_scores_std, alpha=0.3, color='red')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the logistic regression model\n",
    "logistic_model = LogisticRegression(penalty='l2', C=0.01, solver='saga')\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "train_predictions = logistic_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_error = 1 - train_accuracy\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_predictions = logistic_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "val_error = 1 - val_accuracy\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_predictions = logistic_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_error = 1 - test_accuracy\n",
    "\n",
    "# Plot the accuracy and error curves\n",
    "x = ['Training', 'Validation', 'Test']\n",
    "accuracy_values = [train_accuracy, val_accuracy, test_accuracy]\n",
    "error_values = [train_error, val_error, test_error]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, accuracy_values, 'o-', color='b', label='Accuracy')\n",
    "plt.plot(x, error_values, 'o-', color='r', label='Error')\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Accuracy/Error')\n",
    "plt.title('Accuracy and Error on Different Datasets')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpreting Classifiers (example with feature importance for logistic regression)\n",
    "feature_importance = np.abs(logistic_model.coef_[0])\n",
    "sorted_indices = np.argsort(feature_importance)[::-1]\n",
    "top_features = sorted_indices[:10] # Select top 10 important features\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(10), feature_importance[top_features], align='center')\n",
    "plt.xticks(range(10), top_features)\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance for Logistic Regression')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensembles\n",
    "voting_classifier = VotingClassifier([('logistic', logistic_model), ('random_forest', RandomForestClassifier())])\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_voting = voting_classifier.predict(X_test)\n",
    "voting_accuracy = accuracy_score(y_test, y_pred_voting)\n",
    "print(\"Voting Classifier Accuracy:\", voting_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction Speed trained classifier\n",
    "num_samples = 10000\n",
    "X_test_speed = X_test[:num_samples]\n",
    "\n",
    "start_time = time.time()\n",
    "y_pred_speed = logistic_model.predict(X_test_speed)\n",
    "end_time = time.time()\n",
    "\n",
    "prediction_time = (end_time - start_time) * 1000 / num_samples\n",
    "print(\"Prediction Speed (per example):\", prediction_time, \"ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs178",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
